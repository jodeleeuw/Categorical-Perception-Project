setwd("GitHub//Categorical-Perception-Project//data & analysis//raw-data)
require(plyr)
require(sciplot)
require(ez)
require(ggplot2)
require(ggthemes)
#### SECTION: load all data ####
pilotdata <- read.csv2('pilot_flipped_dimensions.csv', quote = "''")
getwd()
setwd("GitHub//Categorical-Perception-Project//data & analysis//raw-data)
getwd()
setwd()
getwd()
setwd("GitHub//Categorical-Perception-Project//data & analysis//raw-data)
getwd()
setwd("GitHub//Categorical-Perception-Project//data & analysis")
require(plyr)
require(sciplot)
require(ez)
require(ggplot2)
require(ggthemes)
#### SECTION: load all data ####
sddata <- read.csv2("raw-data/all_data_sd_task.csv")
xabsimdata <- read.csv2("raw-data/all_data_xab_and_sim_tasks.csv")
alldata <- rbind.fill(xabsimdata,sddata)
#### SECTION: get data columns in proper format ####
alldata$ts          <- strftime(as.POSIXlt(alldata$ts),format='%Y-%m-%d %H:%M:%S')
alldata$distance    <- as.numeric(as.character(alldata$distance))
alldata$xdist       <- as.numeric(as.character(alldata$xdist))
alldata$ydist       <- as.numeric(as.character(alldata$ydist))
alldata$correct     <- as.numeric(as.character(alldata$correct))
alldata$block       <- as.numeric(as.character(alldata$block))
alldata$sim_score   <- as.numeric(as.character(alldata$sim_score))
alldata$rt          <- as.numeric(as.character(alldata$rt))
alldata$trial_index <- as.numeric(as.character(alldata$trial_index))
alldata$trial_idx   <- as.numeric(as.character(alldata$trial_idx))
# the trial_index column was named trial_idx for the xab and sim tasks
# merge both of those columns into one called trial_index
alldata$trial_index <- mapply(function(t1,t2){
if(!is.na(t1)) { return(t1) }
if(!is.na(t2)) { return(t2) }
return(NA)
}, alldata$trial_index, alldata$trial_idx)
# and drop the duplicate column
alldata$trial_idx <- NULL
# add a column that indicates category_type (WITHIN v BETWEEN)
alldata$category_type <- sapply(alldata$comparison_type,function(ct) {
if(ct=="ww" || ct=="pp") { return("WITHIN") }
if(ct=="pw" || ct=="wp") { return("BETWEEN")}
return(NA)
})
#### SECTION: subject count ####
n_subjects <- as.character(unique(alldata$mturk_id))
#### SECTION: filter data ####
### duplicate subjects
# somehow at least one subject did the experiment twice, even though
# this should have been impossible. let's remove all the subjects who
# did the experiment more than once
# filter data to look only at perceptual testing trials
test_data <- alldata[alldata$trial_type == "similarity" | alldata$trial_type == "xab" | alldata$trial_type == "same-different",]
# count how many trials each subject did
# subjects in XAB and SIM conditions should be 144
# subjects in SD condition should be 216
count_by_subj <- ddply(test_data, .(mturk_id), function(subset)with(subset,c(rows=nrow(subset))))
# find all subjects with more than 216 trials
repeat_subjects <- as.character(count_by_subj[count_by_subj$rows > 216,]$mturk_id)
# there are 8 subjects who did this
# filter those subjects out
filterdata <- alldata[!alldata$mturk_id %in% repeat_subjects,]
###
### subjects who failed training
# this function will figure out if someone failed training based on whether their
# accuracy on five consecutive training blocks is below 60%
fail_detector <- function(acc_array){
con_blocks_under = 0
for(i in 1:length(acc_array)){
if(acc_array[i] < 0.60){con_blocks_under = con_blocks_under+1}
else { con_blocks_under = 0}
}
return(con_blocks_under>=5)
}
# this function runs the fail_detector function on each subject and builds a table to determine whether they
# passed or failed training
subject_fail_table <- function(d_block){
b = ddply(d_block, .(block), function(subset)with(subset, c(acc = mean(as.numeric(as.character(correct))))))
c = fail_detector(b$acc)
return(c)
}
# run the subject_fail_table method on the data, fail_subjects will be a list of all the subjects that FAILED training
training_data <- filterdata[filterdata$trial_type == "adaptive_t" | filterdata$trial_type == "adaptive_train",]
df = ddply(training_data, .(mturk_id, exp_condition, stim_type), function(subset)subject_fail_table(subset))
fail_subjects = as.character(df[df$V1=="TRUE",]$mturk_id)
# one subject failed training
# filter out all subjects in the fail_subjects list
filterdata <- filterdata[!filterdata$mturk_id %in% fail_subjects,]
###
### filter out subjects with 0 sd on sim score
# these subjects should be removed because they did not complete
# the task as instructed
sd_by_subj_sim <- ddply(filterdata[filterdata$test_type=="SIM" & filterdata$trial_type=="similarity",], .(mturk_id), function(subset)with(subset,c(sd_sim=sd(sim_score))))
sd_0_subjects <- as.character(sd_by_subj_sim[sd_by_subj_sim$sd_sim==0,]$mturk_id)
# no subjects had this
###
### filter out subjects who pressed the same key for every test trial
# these subjects should be removed because they did not complete
# the task as instructed
sd_key_press <- ddply(filterdata[filterdata$trial_type=="xab" | filterdata$trial_type=="same-different",], .(mturk_id), function(subset)with(subset,c(sd_key=sd(key_press))))
sd_0_key_subjects <- as.character(sd_key_press[sd_key_press$sd==0,]$mturk_id)
# no subjects had this
###
#### SECTION: Subject by condition count ####
subcount <- ddply(filterdata, .(mturk_id, exp_condition), function(subset){return(1)})
table(subcount$exp_condition)
#### SECTION: Trials to complete training ####
# filter the data to look only at training trials
training_trials <- filterdata[filterdata$trial_type=="adaptive_t" | filterdata$trial_type=="adaptive_train",]
# count the number of rows associated with each mturk_id in this data set
training_trial_count <- ddply(training_trials, .(mturk_id, stim_type), function(subset)with(subset, c(len = nrow(subset))))
# visualize trials based on stim type
layout(1)
bargraph.CI(stim_type,len,data=training_trial_count)
# t test
t.test(len ~ stim_type, var.equal=T,data=training_trial_count)
# descriptive stats
sd(training_trial_count[training_trial_count$stim_type=="HD",]$len)
sd(training_trial_count[training_trial_count$stim_type=="LD",]$len)
#### SECTION: Post training category test ####
category_data <- filterdata[filterdata$trial_type=="singleimag",]
#### SECTION: Classic CP analysis (within v. between) ####
# all analyses in this section will restrict to pairs that are only
# 1 or 2 units away on the relevant dimension
# can't use 3 unit pairs because they are ALL between category.
### SD data
sd_classic_cp <- ddply(filterdata[filterdata$trial_type=="same-different" & filterdata$xdist<3 & filterdata$ydist==0 & filterdata$distance>0,],
.(mturk_id, train_type, stim_type, category_type ),
function(subset)with(subset, c(mean_score = mean(correct))))
layout(matrix(1:2, nrow=1))
bargraph.CI(category_type, mean_score, train_type, data = sd_classic_cp[sd_classic_cp$stim_type=="HD",], ylim=c(0,1), main="HD stimuli", ylab="Mean Accuracy", xlab="Category Comparison Type")
bargraph.CI(category_type, mean_score, train_type, data = sd_classic_cp[sd_classic_cp$stim_type=="LD",], ylim=c(0,1), main="LD stimuli", legend=T, xlab="Category Comparison Type")
ezANOVA(data=sd_classic_cp,
dv = .(mean_score),
wid = .(mturk_id),
within = .(category_type),
between = .(stim_type, train_type))
### SIM data
sim_classic_cp <- ddply(filterdata[filterdata$trial_type=="similarity" & filterdata$xdist<3 & filterdata$ydist==0,],
.(mturk_id, train_type, stim_type, category_type ),
function(subset)with(subset, c(mean_score = mean(sim_score))))
layout(matrix(1:2, nrow=1))
bargraph.CI(category_type, mean_score, train_type, data = sim_classic_cp[sim_classic_cp$stim_type=="HD",], ylim=c(0,75), main="HD stimuli", ylab="Mean Similarity Score", xlab="Category Comparison Type")
bargraph.CI(category_type, mean_score, train_type, data = sim_classic_cp[sim_classic_cp$stim_type=="LD",], ylim=c(0,75), main="LD stimuli", legend=T, xlab="Category Comparison Type")
ezANOVA(data=sim_classic_cp,
dv = .(mean_score),
wid = .(mturk_id),
within = .(category_type),
between = .(stim_type, train_type))
# graphing the category_type x train type interaction
bargraph.CI(category_type, mean_score, train_type, data=sim_classic_cp)
### XAB data
xab_classic_cp <- ddply(filterdata[filterdata$trial_type=="xab" & filterdata$xdist<3 & filterdata$ydist==0,],
.(mturk_id, train_type, stim_type, category_type ),
function(subset)with(subset, c(mean_score = mean(correct))))
layout(matrix(1:2, nrow=1))
bargraph.CI(category_type, mean_score, train_type, data = xab_classic_cp[xab_classic_cp$stim_type=="HD",], ylim=c(0.5,0.9), main="HD stimuli", ylab="Mean Accuracy", xlab="Category Comparison Type")
bargraph.CI(category_type, mean_score, train_type, data = xab_classic_cp[xab_classic_cp$stim_type=="LD",], ylim=c(0.5,0.9), main="LD stimuli", legend=T, xlab="Category Comparison Type")
ezANOVA(data=xab_classic_cp,
dv = .(mean_score),
wid = .(mturk_id),
within = .(category_type),
between = .(stim_type, train_type))
View(sd_classic_cp)
sd_classic_cp$train_type == "CONTROL"
x <- sd_classic_cp[sd_classic_cp$train_type == "CONTROL"]
x <- sd_classic_cp[sd_classic_cp$train_type == "CONTROL",]
x
x$mean_score
mean(x$mean_score)
x <- sd_classic_cp[sd_classic_cp$train_type == "TRAIN",]
x
mean(x$mean_score)
